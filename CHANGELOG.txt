Change Log
==========

0.1.3 (07/10/2020)
-----------------
* Bug fix in apply_on_states invocation of callbacks 


0.1.2 (07/10/2020)
-----------------
* Readme fix 


0.1.1 (07/10/2020)
-----------------
* Added TEST_BEGIN and TEST_END callbacks phases
* Added CallbackMonitor
* Added enums (lpd.enums) TrainerState, MonitorType, MonitorMode, StatsType


0.1.0 (05/10/2020)
-----------------
* Introduced CallbackPhase and State to control timing of callback invocation
* Added example of SchedulerStep every batch in train state
* Trainer support for native pytorch dataloader
* Added data loader example


0.0.9 (04/10/2020)
-----------------
* Added support for setting trainer's scheduler to None
* Added name property to trainer
* Added trainer's description
* Added last train/val/test loss objects
* Reduce package size by moving images to another repo 
* Added another example "Basic"
* If no metrics provided, EpochEndStats will print "no metrics found"
* Fixed trainer crash if no metric_name_to_func was provided
* Added seed_all to general_utils
* Added seed_torch to torch_utils
* Added readme about utils


0.0.8 (03/10/2020)
-----------------
* Added optional round_values_on_print_to to EpochEndStats and ModelCheckPoint callbacks
* Removed round_values_to from TrainerStats & Stats (it didnt made sense anyway)
* Removed print_round_values_to from trainer, its now on the callbacks themselves
* Updated readme


0.0.7 (03/10/2020)
-----------------
* Splited TrainerStats class into TrainerStats & Stats
* Can now easily call trainer.train_stats.get_loss() or trainer.val_stats.get_metrics()
* TrainerStats now has a reset() function
* Using configs in example 
* Code clean up and cosmetics


0.0.6 (02/10/2020)
-----------------
* Scheduler step as callback, support for step() with or without parameters


0.0.1 (01/10/2020)
-----------------
- First Release